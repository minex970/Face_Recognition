{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbe2b8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALL modules...\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.base import MIMEBase\n",
    "from email import encoders\n",
    "import getpass\n",
    "\n",
    "import pywhatkit as kit\n",
    "\n",
    "import subprocess as s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72a9116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45b5f18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def email(face): \n",
    "    passwd = getpass.getpass(\"Enter the Sender Email password :\")\n",
    "    fromaddr = \"test.project970@gmail.com\"\n",
    "    toaddr = \"gneeraj970@gmail.com\"\n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = fromaddr\n",
    "    msg['To'] = toaddr\n",
    "    msg['Subject'] = \"Face Reognized\"\n",
    "    body = \"Hurray Your Face Recognition code working !!!!\"\n",
    "    msg.attach(MIMEText(body, 'plain'))\n",
    "\n",
    "    filename = face\n",
    "    attachment = open(r\"./\"+face, \"rb\")\n",
    "\n",
    "    p = MIMEBase('application', 'octet-stream')\n",
    "    p.set_payload((attachment).read())\n",
    "    encoders.encode_base64(p)\n",
    "    p.add_header('Content-Disposition', \"attachment; filename= %s\" % filename)\n",
    "    msg.attach(p)\n",
    "    s = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "    s.starttls()\n",
    "    s.login(fromaddr,passwd)\n",
    "    text = msg.as_string()\n",
    "    s.sendmail(fromaddr,toaddr,text)\n",
    "    s.quit()\n",
    "    print(\"\\nMail sent....check Inbox !!!!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7d4b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def whatsapp():\n",
    "    phone = input(\"Enter your's friend number: \")\n",
    "    kit.sendwhatmsg_instantly(\"+91\"+phone,\"Security Alert : Someone Face has been Detected\" ,20 ,False)\n",
    "    print(\"whatsapp msg sent !!!!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dc0a4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aws():\n",
    "    \n",
    "#Launching EC2 Instance\n",
    "    instances = input(\"Enter instances type: \")\n",
    "    value = input(\"Enter the name for your instances: \")\n",
    "    print(\"launching instances...\\napproximately it's take 2-3 mins to launch.\")\n",
    "    \n",
    "    output1 = s.getstatusoutput(\"aws ec2 run-instances --image-id ami-011c99152163a87ae  --count 1 --instance-type {} --key-name task6 --security-group-ids sg-07108f193958782d9 --subnet-id subnet-5dede435\".format(instances))\n",
    "    instance_id = output1[1][157:176]\n",
    "    tmp = s.getstatusoutput(\"aws ec2 create-tags --resources {} --tags Key=Name,Value={}\".format(instance_id,value))\n",
    "    time.sleep(180)\n",
    "    print(\"Instances created.\\n\")\n",
    "\n",
    "#Creating EBS volume\n",
    "    \n",
    "    size = input(\"Enter the size of EBS volume(in GB): \")\n",
    "    name = input(\"Enter the name for your volume:\")\n",
    "    print(\"Creating EBS volume...\")\n",
    "    output2 = s.getstatusoutput(\"aws ec2 create-volume --volume-type gp2  --size {} --availability-zone ap-south-1a\".format(size))\n",
    "    vol_id = output2[1][191:212]\n",
    "    tmp = s.getstatusoutput(\"aws ec2 create-tags --resources {} --tags Key=Name,Value={}\".format(vol_id,name))\n",
    "    print(\"Volume created.\\n\")\n",
    "\n",
    "#Attaching the EBS Volume to the EC2 Instance\n",
    "    print(\"Attaching the EBS volume...\")\n",
    "    tmp = s.getstatusoutput(\"aws ec2 attach-volume --volume-id {} --instance-id {} --device /dev/sdf\".format(vol_id,instance_id))\n",
    "    print(\"Successfully attach EBS volume to instances.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d22a3346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-6-fcc5a1418afe>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting 100 samples of your face...\n",
      "Faces sample 1\n",
      "Faces sample 2\n",
      "Faces sample 3\n",
      "Faces sample 4\n",
      "Faces sample 5\n",
      "Faces sample 6\n",
      "Faces sample 7\n",
      "Faces sample 8\n",
      "Faces sample 9\n",
      "Faces sample 10\n",
      "Faces sample 11\n",
      "Faces sample 12\n",
      "Faces sample 13\n",
      "Faces sample 14\n",
      "Faces sample 15\n",
      "Faces sample 16\n",
      "Faces sample 17\n",
      "Faces sample 18\n",
      "Faces sample 19\n",
      "Faces sample 20\n",
      "Faces sample 21\n",
      "Faces sample 22\n",
      "Faces sample 23\n",
      "Faces sample 24\n",
      "Faces sample 25\n",
      "Faces sample 26\n",
      "Faces sample 27\n",
      "Faces sample 28\n",
      "Faces sample 29\n",
      "Faces sample 30\n",
      "Faces sample 31\n",
      "Faces sample 32\n",
      "Faces sample 33\n",
      "Faces sample 34\n",
      "Faces sample 35\n",
      "Faces sample 36\n",
      "Faces sample 37\n",
      "Faces sample 38\n",
      "Faces sample 39\n",
      "Faces sample 40\n",
      "Faces sample 41\n",
      "Faces sample 42\n",
      "Faces sample 43\n",
      "Faces sample 44\n",
      "Faces sample 45\n",
      "Faces sample 46\n",
      "Faces sample 47\n",
      "Faces sample 48\n",
      "Faces sample 49\n",
      "Faces sample 50\n",
      "Faces sample 51\n",
      "Faces sample 52\n",
      "Faces sample 53\n",
      "Faces sample 54\n",
      "Faces sample 55\n",
      "Faces sample 56\n",
      "Faces sample 57\n",
      "Faces sample 58\n",
      "Faces sample 59\n",
      "Faces sample 60\n",
      "Faces sample 61\n",
      "Faces sample 62\n",
      "Faces sample 63\n",
      "Faces sample 64\n",
      "Faces sample 65\n",
      "Faces sample 66\n",
      "Faces sample 67\n",
      "Faces sample 68\n",
      "Faces sample 69\n",
      "Faces sample 70\n",
      "Faces sample 71\n",
      "Faces sample 72\n",
      "Faces sample 73\n",
      "Faces sample 74\n",
      "Faces sample 75\n",
      "Faces sample 76\n",
      "Faces sample 77\n",
      "Faces sample 78\n",
      "Faces sample 79\n",
      "Faces sample 80\n",
      "Faces sample 81\n",
      "Faces sample 82\n",
      "Faces sample 83\n",
      "Faces sample 84\n",
      "Faces sample 85\n",
      "Faces sample 86\n",
      "Faces sample 87\n",
      "Faces sample 88\n",
      "Faces sample 89\n",
      "Faces sample 90\n",
      "Faces sample 91\n",
      "Faces sample 92\n",
      "Faces sample 93\n",
      "Faces sample 94\n",
      "Faces sample 95\n",
      "Faces sample 96\n",
      "Faces sample 97\n",
      "Faces sample 98\n",
      "Faces sample 99\n",
      "Faces sample 100\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    " ## Collecting Images\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "print(\"collecting 100 samples of your face...\")\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None :\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = './faces/' + 'grp4-'  + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropped', face)\n",
    "        print(\"Faces sample {}\".format(count))        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8ff9faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained sucessefully\n"
     ]
    }
   ],
   "source": [
    " ## Training Model\n",
    "\n",
    "# Get the training data we previously made\n",
    "data_path = './faces/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "# Initialize facial recognizer\n",
    "# model = cv2.face.createLBPHFaceRecognizer()\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "# pip install opencv-contrib-python\n",
    "# model = cv2.createLBPHFaceRecognizer()\n",
    "\n",
    "model  = cv2.face_LBPHFaceRecognizer.create()\n",
    "# Let's train our model \n",
    "model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model trained sucessefully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c5dd1",
   "metadata": {},
   "source": [
    "## 6.1- If the Face Recognise then send email to us and WhatsApp to your friend.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f04a152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-8-77371b09e2c2>:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Sender Email password :········\n",
      "\n",
      "Mail sent....check Inbox !!!!\n",
      "\n",
      "Enter your's friend number: 9152538805\n",
      "whatsapp msg sent !!!!\n",
      "\n",
      "ALL set...!!!\n",
      "Done with Task-6.1\n"
     ]
    }
   ],
   "source": [
    " ## Face Recognise\n",
    "\n",
    "def face_detector(img, size=0.5):    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "       \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()    \n",
    "    image, face = face_detector(frame)    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        results = model.predict(face)\n",
    "        # harry_model.predict(face)\n",
    "        \n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User'\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        if confidence > 75:\n",
    "            cv2.putText(image, \"Neeraj's photo\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image)\n",
    "            cv2.imwrite(\"neeraj(6.1).jpg\" , image)\n",
    "            email(\"neeraj(6.1).jpg\")\n",
    "            whatsapp() \n",
    "            break        \n",
    "        else:     \n",
    "            cv2.putText(image, \"U R FRIEND!!!, how r u\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"ALL set...!!!\\nDone with Task-6.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507e3440",
   "metadata": {},
   "source": [
    "## 6.2- If the Face Recognise then launch EC2 instance, EBS volume and attach it to the instance.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83306b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-9-2928196e658c>:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter instances type: t2.micro\n",
      "Enter the name for your instances: Task-6\n",
      "launching instances...\n",
      "approximately it's take 2-3 mins to launch.\n",
      "Instances created.\n",
      "\n",
      "Enter the size of EBS volume(in GB): 5\n",
      "Enter the name for your volume:Task-6 EBS\n",
      "Creating EBS volume...\n",
      "Volume created.\n",
      "\n",
      "Attaching the EBS volume...\n",
      "Successfully attach EBS volume to instances.\n",
      "ALL set...!!!\n",
      "Done with Task-6.2\n"
     ]
    }
   ],
   "source": [
    "## Face Recognise\n",
    "\n",
    "def face_detector(img, size=0.5):   \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()    \n",
    "    image, face = face_detector(frame)    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        results = model.predict(face)\n",
    "        # harry_model.predict(face)\n",
    "        \n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User'\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        if confidence > 85:\n",
    "            cv2.putText(image, \"Neeraj's second photo\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image)\n",
    "            cv2.imwrite(\"neeraj(6.2).jpg\" , image)\n",
    "            aws()\n",
    "            break         \n",
    "        else:            \n",
    "            cv2.putText(image, \"U R FRIEND!!!, how r u\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"ALL set...!!!\\nDone with Task-6.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60cbb32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
